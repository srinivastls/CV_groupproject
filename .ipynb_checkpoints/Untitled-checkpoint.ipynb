{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "405b6198",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "NewRandomAccessFile failed to Create/Open: model/binary_128_0.50_labels_ver2.txt : The system cannot find the path specified.\r\n; No such process",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 414\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    412\u001b[0m     findPlate \u001b[38;5;241m=\u001b[39m PlateFinder(minPlateArea\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, \n\u001b[0;32m    413\u001b[0m                                 maxPlateArea\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15000\u001b[39m)\n\u001b[1;32m--> 414\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mOCR\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodelFile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel/binary_128_0.50_ver3.pb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabelFile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel/binary_128_0.50_labels_ver2.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    416\u001b[0m     cap \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest.mov\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m (cap\u001b[38;5;241m.\u001b[39misOpened()):\n",
      "Cell \u001b[1;32mIn[1], line 337\u001b[0m, in \u001b[0;36mOCR.__init__\u001b[1;34m(self, modelFile, labelFile)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_file \u001b[38;5;241m=\u001b[39m modelFile\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_file \u001b[38;5;241m=\u001b[39m labelFile\n\u001b[1;32m--> 337\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_label\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_graph(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_file)\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msess \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mSession(graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph, \n\u001b[0;32m    340\u001b[0m                                  config\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mConfigProto())\n",
      "Cell \u001b[1;32mIn[1], line 357\u001b[0m, in \u001b[0;36mOCR.load_label\u001b[1;34m(self, labelFile)\u001b[0m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_label\u001b[39m(\u001b[38;5;28mself\u001b[39m, labelFile):\n\u001b[0;32m    356\u001b[0m     label \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 357\u001b[0m     proto_as_ascii_lines \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabelFile\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadlines\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m proto_as_ascii_lines:\n\u001b[0;32m    360\u001b[0m         label\u001b[38;5;241m.\u001b[39mappend(l\u001b[38;5;241m.\u001b[39mrstrip())\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:174\u001b[0m, in \u001b[0;36mFileIO.readlines\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreadlines\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    173\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns all lines from the file in a list.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 174\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_preread_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m   lines \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    176\u001b[0m   \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:77\u001b[0m, in \u001b[0;36mFileIO._preread_check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_check_passed:\n\u001b[0;32m     75\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mPermissionDeniedError(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     76\u001b[0m                                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt open for reading\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_buf \u001b[38;5;241m=\u001b[39m \u001b[43m_pywrap_file_io\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBufferedInputStream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath_to_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: NewRandomAccessFile failed to Create/Open: model/binary_128_0.50_labels_ver2.txt : The system cannot find the path specified.\r\n; No such process"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.filters import threshold_local\n",
    "import tensorflow as tf\n",
    "from skimage import measure\n",
    "import imutils\n",
    "import os\n",
    "  \n",
    "def sort_cont(character_contours):\n",
    "    \"\"\"\n",
    "    To sort contours\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    boundingBoxes = [cv2.boundingRect(c) for c in character_contours]\n",
    "      \n",
    "    (character_contours, boundingBoxes) = zip(*sorted(zip(character_contours,\n",
    "                                                          boundingBoxes),\n",
    "                                                      key = lambda b: b[1][i],\n",
    "                                                      reverse = False))\n",
    "      \n",
    "    return character_contours\n",
    "  \n",
    "  \n",
    "def segment_chars(plate_img, fixed_width):\n",
    "      \n",
    "    \"\"\"\n",
    "    extract Value channel from the HSV format\n",
    "    of image and apply adaptive thresholding\n",
    "    to reveal the characters on the license plate\n",
    "    \"\"\"\n",
    "    V = cv2.split(cv2.cvtColor(plate_img, cv2.COLOR_BGR2HSV))[2]\n",
    " \n",
    "    thresh = cv2.adaptiveThreshold(V, 255,\n",
    "                                   cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                   cv2.THRESH_BINARY,\n",
    "                                   11, 2)\n",
    "   \n",
    "    thresh = cv2.bitwise_not(thresh)\n",
    "  \n",
    "    # resize the license plate region to\n",
    "    # a canoncial size\n",
    "    plate_img = imutils.resize(plate_img, width = fixed_width)\n",
    "    thresh = imutils.resize(thresh, width = fixed_width)\n",
    "    bgr_thresh = cv2.cvtColor(thresh, cv2.COLOR_GRAY2BGR)\n",
    "  \n",
    "    # perform a connected components analysis\n",
    "    # and initialize the mask to store the locations\n",
    "    # of the character candidates\n",
    "    labels = measure.label(thresh, background = 0)\n",
    "  \n",
    "    charCandidates = np.zeros(thresh.shape, dtype ='uint8')\n",
    "  \n",
    "    # loop over the unique components\n",
    "    characters = []\n",
    "    for label in np.unique(labels):\n",
    "          \n",
    "        # if this is the background label, ignore it\n",
    "        if label == 0:\n",
    "            continue\n",
    "        # otherwise, construct the label mask to display\n",
    "        # only connected components for the current label,\n",
    "        # then find contours in the label mask\n",
    "        labelMask = np.zeros(thresh.shape, dtype ='uint8')\n",
    "        labelMask[labels == label] = 255\n",
    "  \n",
    "        cnts = cv2.findContours(labelMask,\n",
    "                     cv2.RETR_EXTERNAL,\n",
    "                     cv2.CHAIN_APPROX_SIMPLE)\n",
    " \n",
    "        cnts = cnts[1] if imutils.is_cv3() else cnts[0]\n",
    "  \n",
    "        # ensure at least one contour was found in the mask\n",
    "        if len(cnts) > 0:\n",
    "  \n",
    "            # grab the largest contour which corresponds\n",
    "            # to the component in the mask, then grab the\n",
    "            # bounding box for the contour\n",
    "            c = max(cnts, key = cv2.contourArea)\n",
    "            (boxX, boxY, boxW, boxH) = cv2.boundingRect(c)\n",
    "  \n",
    "            # compute the aspect ratio, solodity, and\n",
    "            # height ration for the component\n",
    "            aspectRatio = boxW / float(boxH)\n",
    "            solidity = cv2.contourArea(c) / float(boxW * boxH)\n",
    "            heightRatio = boxH / float(plate_img.shape[0])\n",
    "  \n",
    "            # determine if the aspect ratio, solidity,\n",
    "            # and height of the contour pass the rules\n",
    "            # tests\n",
    "            keepAspectRatio = aspectRatio < 1.0\n",
    "            keepSolidity = solidity > 0.15\n",
    "            keepHeight = heightRatio > 0.5 and heightRatio < 0.95\n",
    "  \n",
    "            # check to see if the component passes\n",
    "            # all the tests\n",
    "            if keepAspectRatio and keepSolidity and keepHeight and boxW > 14:\n",
    "                  \n",
    "                # compute the convex hull of the contour\n",
    "                # and draw it on the character candidates\n",
    "                # mask\n",
    "                hull = cv2.convexHull(c)\n",
    "  \n",
    "                cv2.drawContours(charCandidates, [hull], -1, 255, -1)\n",
    "  \n",
    "    contours, hier = cv2.findContours(charCandidates,\n",
    "                                         cv2.RETR_EXTERNAL,\n",
    "                                         cv2.CHAIN_APPROX_SIMPLE)\n",
    "      \n",
    "    if contours:\n",
    "        contours = sort_cont(contours)\n",
    "          \n",
    "        # value to be added to each dimension\n",
    "        # of the character\n",
    "        addPixel = 4\n",
    "        for c in contours:\n",
    "            (x, y, w, h) = cv2.boundingRect(c)\n",
    "            if y > addPixel:\n",
    "                y = y - addPixel\n",
    "            else:\n",
    "                y = 0\n",
    "            if x > addPixel:\n",
    "                x = x - addPixel\n",
    "            else:\n",
    "                x = 0\n",
    "            temp = bgr_thresh[y:y + h + (addPixel * 2),\n",
    "                              x:x + w + (addPixel * 2)]\n",
    "  \n",
    "            characters.append(temp)\n",
    "              \n",
    "        return characters\n",
    "      \n",
    "    else:\n",
    "        return None\n",
    "  \n",
    "  \n",
    "  \n",
    "class PlateFinder:\n",
    "    def __init__(self, minPlateArea, maxPlateArea):\n",
    "          \n",
    "        # minimum area of the plate\n",
    "        self.min_area = minPlateArea\n",
    "          \n",
    "        # maximum area of the plate\n",
    "        self.max_area = maxPlateArea \n",
    "  \n",
    "        self.element_structure = cv2.getStructuringElement(\n",
    "                              shape = cv2.MORPH_RECT, ksize =(22, 3))\n",
    "  \n",
    "    def preprocess(self, input_img):\n",
    "          \n",
    "        imgBlurred = cv2.GaussianBlur(input_img, (7, 7), 0)\n",
    "          \n",
    "        # convert to gray\n",
    "        gray = cv2.cvtColor(imgBlurred, cv2.COLOR_BGR2GRAY)\n",
    "          \n",
    "        # sobelX to get the vertical edges\n",
    "        sobelx = cv2.Sobel(gray, cv2.CV_8U, 1, 0, ksize = 3) \n",
    "          \n",
    "        # otsu's thresholding\n",
    "        ret2, threshold_img = cv2.threshold(sobelx, 0, 255,\n",
    "                         cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "  \n",
    "        element = self.element_structure\n",
    "        morph_n_thresholded_img = threshold_img.copy()\n",
    "        cv2.morphologyEx(src = threshold_img,\n",
    "                         op = cv2.MORPH_CLOSE,\n",
    "                         kernel = element,\n",
    "                         dst = morph_n_thresholded_img)\n",
    "          \n",
    "        return morph_n_thresholded_img\n",
    "  \n",
    "    def extract_contours(self, after_preprocess):\n",
    "          \n",
    "        contours, _ = cv2.findContours(after_preprocess,\n",
    "                                          mode = cv2.RETR_EXTERNAL,\n",
    "                                          method = cv2.CHAIN_APPROX_NONE)\n",
    "        return contours\n",
    "  \n",
    "    def clean_plate(self, plate):\n",
    "          \n",
    "        gray = cv2.cvtColor(plate, cv2.COLOR_BGR2GRAY)\n",
    "        thresh = cv2.adaptiveThreshold(gray,\n",
    "                                       255,\n",
    "                                       cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                       cv2.THRESH_BINARY,\n",
    "                                       11, 2)\n",
    "          \n",
    "        contours, _ = cv2.findContours(thresh.copy(),\n",
    "                                          cv2.RETR_EXTERNAL,\n",
    "                                          cv2.CHAIN_APPROX_NONE)\n",
    "  \n",
    "        if contours:\n",
    "            areas = [cv2.contourArea(c) for c in contours]\n",
    "              \n",
    "            # index of the largest contour in the area\n",
    "            # array\n",
    "            max_index = np.argmax(areas) \n",
    "  \n",
    "            max_cnt = contours[max_index]\n",
    "            max_cntArea = areas[max_index]\n",
    "            x, y, w, h = cv2.boundingRect(max_cnt)\n",
    "            rect = cv2.minAreaRect(max_cnt)\n",
    "            if not self.ratioCheck(max_cntArea, plate.shape[1],\n",
    "                                                plate.shape[0]):\n",
    "                return plate, False, None\n",
    "              \n",
    "            return plate, True, [x, y, w, h]\n",
    "          \n",
    "        else:\n",
    "            return plate, False, None\n",
    "  \n",
    "  \n",
    "  \n",
    "    def check_plate(self, input_img, contour):\n",
    "          \n",
    "        min_rect = cv2.minAreaRect(contour)\n",
    "          \n",
    "        if self.validateRatio(min_rect):\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            after_validation_img = input_img[y:y + h, x:x + w]\n",
    "            after_clean_plate_img, plateFound, coordinates = self.clean_plate(\n",
    "                                                        after_validation_img)\n",
    "              \n",
    "            if plateFound:\n",
    "                characters_on_plate = self.find_characters_on_plate(\n",
    "                                              after_clean_plate_img)\n",
    "                  \n",
    "                if (characters_on_plate is not None and len(characters_on_plate) == 8):\n",
    "                    x1, y1, w1, h1 = coordinates\n",
    "                    coordinates = x1 + x, y1 + y\n",
    "                    after_check_plate_img = after_clean_plate_img\n",
    "                      \n",
    "                    return after_check_plate_img, characters_on_plate, coordinates\n",
    "          \n",
    "        return None, None, None\n",
    "  \n",
    "  \n",
    "  \n",
    "    def find_possible_plates(self, input_img):\n",
    "          \n",
    "        \"\"\"\n",
    "        Finding all possible contours that can be plates\n",
    "        \"\"\"\n",
    "        plates = []\n",
    "        self.char_on_plate = []\n",
    "        self.corresponding_area = []\n",
    "  \n",
    "        self.after_preprocess = self.preprocess(input_img)\n",
    "        possible_plate_contours = self.extract_contours(self.after_preprocess)\n",
    "  \n",
    "        for cnts in possible_plate_contours:\n",
    "            plate, characters_on_plate, coordinates = self.check_plate(input_img, cnts)\n",
    "              \n",
    "            if plate is not None:\n",
    "                plates.append(plate)\n",
    "                self.char_on_plate.append(characters_on_plate)\n",
    "                self.corresponding_area.append(coordinates)\n",
    "  \n",
    "        if (len(plates) > 0):\n",
    "            return plates\n",
    "          \n",
    "        else:\n",
    "            return None\n",
    "  \n",
    "    def find_characters_on_plate(self, plate):\n",
    "  \n",
    "        charactersFound = segment_chars(plate, 400)\n",
    "        if charactersFound:\n",
    "            return charactersFound\n",
    "  \n",
    "    # PLATE FEATURES\n",
    "    def ratioCheck(self, area, width, height):\n",
    "          \n",
    "        min = self.min_area\n",
    "        max = self.max_area\n",
    "  \n",
    "        ratioMin = 3\n",
    "        ratioMax = 6\n",
    "  \n",
    "        ratio = float(width) / float(height)\n",
    "          \n",
    "        if ratio < 1:\n",
    "            ratio = 1 / ratio\n",
    "          \n",
    "        if (area < min or area > max) or (ratio < ratioMin or ratio > ratioMax):\n",
    "            return False\n",
    "          \n",
    "        return True\n",
    "  \n",
    "    def preRatioCheck(self, area, width, height):\n",
    "          \n",
    "        min = self.min_area\n",
    "        max = self.max_area\n",
    "  \n",
    "        ratioMin = 2.5\n",
    "        ratioMax = 7\n",
    "  \n",
    "        ratio = float(width) / float(height)\n",
    "          \n",
    "        if ratio < 1:\n",
    "            ratio = 1 / ratio\n",
    "  \n",
    "        if (area < min or area > max) or (ratio < ratioMin or ratio > ratioMax):\n",
    "            return False\n",
    "          \n",
    "        return True\n",
    "  \n",
    "    def validateRatio(self, rect):\n",
    "        (x, y), (width, height), rect_angle = rect\n",
    "  \n",
    "        if (width > height):\n",
    "            angle = -rect_angle\n",
    "        else:\n",
    "            angle = 90 + rect_angle\n",
    "  \n",
    "        if angle > 15:\n",
    "            return False\n",
    "          \n",
    "        if (height == 0 or width == 0):\n",
    "            return False\n",
    "  \n",
    "        area = width * height\n",
    "          \n",
    "        if not self.preRatioCheck(area, width, height):\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "        \n",
    "        \n",
    "        \n",
    "class OCR:\n",
    "      \n",
    "    def __init__(self, modelFile, labelFile):\n",
    "          \n",
    "        self.model_file = modelFile\n",
    "        self.label_file = labelFile\n",
    "        self.label = self.load_label(self.label_file)\n",
    "        self.graph = self.load_graph(self.model_file)\n",
    "        self.sess = tf.compat.v1.Session(graph=self.graph, \n",
    "                                         config=tf.compat.v1.ConfigProto())\n",
    "  \n",
    "    def load_graph(self, modelFile):\n",
    "          \n",
    "        graph = tf.Graph()\n",
    "        graph_def = tf.compat.v1.GraphDef()\n",
    "          \n",
    "        with open(modelFile, \"rb\") as f:\n",
    "            graph_def.ParseFromString(f.read())\n",
    "          \n",
    "        with graph.as_default():\n",
    "            tf.import_graph_def(graph_def)\n",
    "          \n",
    "        return graph\n",
    "  \n",
    "    def load_label(self, labelFile):\n",
    "        label = []\n",
    "        proto_as_ascii_lines = tf.io.gfile.GFile(labelFile).readlines()\n",
    "          \n",
    "        for l in proto_as_ascii_lines:\n",
    "            label.append(l.rstrip())\n",
    "          \n",
    "        return label\n",
    "  \n",
    "    def convert_tensor(self, image, imageSizeOuput):\n",
    "        \"\"\"\n",
    "        takes an image and transform it in tensor\n",
    "        \"\"\"\n",
    "        image = cv2.resize(image,\n",
    "                           dsize =(imageSizeOuput,\n",
    "                                  imageSizeOuput),\n",
    "                           interpolation = cv2.INTER_CUBIC)\n",
    "          \n",
    "        np_image_data = np.asarray(image)\n",
    "        np_image_data = cv2.normalize(np_image_data.astype('float'),\n",
    "                                      None, -0.5, .5,\n",
    "                                      cv2.NORM_MINMAX)\n",
    "          \n",
    "        np_final = np.expand_dims(np_image_data, axis = 0)\n",
    "          \n",
    "        return np_final\n",
    "  \n",
    "    def label_image(self, tensor):\n",
    "  \n",
    "        input_name = \"import/input\"\n",
    "        output_name = \"import/final_result\"\n",
    "  \n",
    "        input_operation = self.graph.get_operation_by_name(input_name)\n",
    "        output_operation = self.graph.get_operation_by_name(output_name)\n",
    "  \n",
    "        results = self.sess.run(output_operation.outputs[0],\n",
    "                                {input_operation.outputs[0]: tensor})\n",
    "        results = np.squeeze(results)\n",
    "        labels = self.label\n",
    "        top = results.argsort()[-1:][::-1]\n",
    "          \n",
    "        return labels[top[0]]\n",
    "  \n",
    "    def label_image_list(self, listImages, imageSizeOuput):\n",
    "        plate = \"\"\n",
    "          \n",
    "        for img in listImages:\n",
    "              \n",
    "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                break\n",
    "            plate = plate + self.label_image(self.convert_tensor(img, imageSizeOuput))\n",
    "          \n",
    "        return plate, len(plate)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "      \n",
    "    findPlate = PlateFinder(minPlateArea=100, \n",
    "                                maxPlateArea=15000)\n",
    "    model = OCR(modelFile=\"model/binary_128_0.50_ver3.pb\", labelFile=\"model/binary_128_0.50_labels_ver2.txt\")\n",
    "  \n",
    "    cap = cv2.VideoCapture('test.mov')\n",
    "      \n",
    "    while (cap.isOpened()):\n",
    "        ret, img = cap.read()\n",
    "          \n",
    "        if ret == True:\n",
    "            cv2.imshow('original video', img)\n",
    "              \n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "              \n",
    "            possible_plates = findPlate.find_possible_plates(img)\n",
    "            if possible_plates is not None:\n",
    "                  \n",
    "                for i, p in enumerate(possible_plates):\n",
    "                    chars_on_plate = findPlate.char_on_plate[i]\n",
    "                    recognized_plate, _ = model.label_image_list(\n",
    "                               chars_on_plate, imageSizeOuput = 128)\n",
    "  \n",
    "                    print(recognized_plate)\n",
    "                    cv2.imshow('plate', p)\n",
    "                      \n",
    "                    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                        break\n",
    "        else:\n",
    "            break\n",
    "              \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cde920c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
